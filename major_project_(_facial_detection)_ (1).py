# -*- coding: utf-8 -*-
"""MAJOR PROJECT ( FACIAL DETECTION) .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BFYyVXd5RfV6sgysHkKoE-SpkHr-q9Rv

## Importing python libraries
"""

!pip install cmake
!pip install dlib
!pip3 install face_recognition

from PIL import Image
from matplotlib import pyplot as plt
import numpy as np
import keras
from keras.models import load_model
import cv2
import face_recognition

!pip freeze> requirements.txt

"""## Face Detection

### Sample Image
"""

image1 = Image.open("")
image_array1 = np.array(image1)
plt.imshow(image_array1)

"""## Face Detection

### Detecting the location of faces from a given image using face_recognition library
"""

image = face_recognition.load_image_file("")

face_locations = face_recognition.face_locations(image)

"""#### A list of tuples of found face locations in (top, right, bottom, left) order"""

face_locations

"""#### Taking the first face detected from image and plotting it"""

top, right, bottom, left = face_locations[0]
face_image1 = image[top:bottom, left:right]
plt.imshow(face_image1)
image_save = Image.fromarray(face_image1)
image_save.save("image_1.jpg")

"""#### Taking the second face detected from image and plotting it"""

top, right, bottom, left = face_locations[1]
face_image2 = image[top:bottom, left:right]
plt.imshow(face_image2)
image_save = Image.fromarray(face_image2)
image_save.save("image_2.jpg")

"""## Face Recognition

### Image1
"""

image1 = Image.open("/content/sample_data/IMG_20211005_145235.jpg")
image_array1 = np.array(image1)
plt.imshow(image_array1)

"""### Image2"""

image2 = Image.open("/content/sample_data/IMG_20211005_145235.jpg")
image_array2 = np.array(image2)
plt.imshow(image_array2)

"""### Image3"""

image3 = Image.open("/content/sample_data/IMG-20210731-WA0057 (1).jpg")
image_array3 = np.array(image3)
plt.imshow(image_array3)

"""### find the face encoding for Image1 and Image2 which is of same person with different pose and compare them to find if they are recognized as same"""

image1 = face_recognition.load_image_file("/content/sample_data/IMG_20211005_145229.jpg")
image2 = face_recognition.load_image_file("/content/sample_data/IMG_20211005_145229.jpg")
 
encoding_1 = face_recognition.face_encodings(image1)[0]

encoding_2 = face_recognition.face_encodings(image1)[0]

results = face_recognition.compare_faces([encoding_1], encoding_2,tolerance=0.50)

"""### the result of the above comparison returns "True" stating that two images having different pose are recognized as same"""

print(results)

"""### the same is done for Image1 and Image3 which are the images of two persons and the result returned after comparison is "False" denoting the two images are not recognized as same"""

image1 = face_recognition.load_image_file("/content/sample_data/IMG_20211005_145229.jpg")
image2 = face_recognition.load_image_file("/content/sample_data/IMG_20211005_145229.jpg")
 
encoding_1 = face_recognition.face_encodings(image1)[0]

encoding_2 = face_recognition.face_encodings(image2)[0]

results = face_recognition.compare_faces([encoding_1], encoding_2,tolerance=0.50)

print(results)

"""## Emotion detection"""

emotion_dict= {'Angry': 0, 'Sad': 5, 'Neutral': 4, 'Disgust': 1, 'Surprise': 6, 'Fear': 2, 'Happy': 3}

"""### Reading a sample image """

face_image  = cv2.imread("/content/sample_data/IMG_20211005_145229.jpg")
plt.imshow(face_image)

"""### The label of this image is "Surprise""""

print face_image.shape

# image = face_recognition.load_image_file("/content/sample_data/IMG_20211005_145229.jpg")
# face_locations = face_recognition.face_locations(face_image)
# top, right, bottom, left = face_locations[0]
# face_image = face_image[top:bottom, left:right]
# plt.imshow(face_image)

# resizing the image
face_image = cv2.resize(face_image, (48,48))
face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
face_image = np.reshape(face_image, [1, face_image.shape[0], face_image.shape[1], 1])

"""

### Load the model trained for detecting emotions of a face"""

model = load_model("../emotion_detector_models/model_v6_23.hdf5")

print face_image.shape

predicted_class = np.argmax(model.predict(face_image))

"""### Predicted label"""

label_map = dict((v,k) for k,v in emotion_dict.items()) 
predicted_label = label_map[predicted_class]

print(predicted_label)

